import streamlit as st
import anthropic
import openai
import tempfile
import time
from datetime import datetime, timedelta, timezone
import zipfile
import io
import os
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
import subprocess
import json
import re
import urllib.request
import uuid
from celery import Celery
import redis

# ë¬¸ì„œ ìƒì„±ìš©
from docx import Document
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
from docx.oxml import OxmlElement

# ============================================
# Celery ì„¤ì •
# ============================================
# Redisë¥¼ ë©”ì‹œì§€ ë¸Œë¡œì»¤ë¡œ ì‚¬ìš©
app = Celery('interview_tasks', broker='redis://localhost:6379/0')
app.conf.result_backend = 'redis://localhost:6379/0'
app.conf.task_track_started = True

# Redis í´ë¼ì´ì–¸íŠ¸
redis_client = redis.StrictRedis(host='localhost', port=6379, db=0, decode_responses=True)

# í˜ì´ì§€ ì„¤ì • - ì‚¬ì´ë“œë°” ìˆ¨ê¹€
st.set_page_config(
    page_title="ìºí”¼ ì¸í„°ë·°",
    page_icon="ğŸ˜Š",
    layout="centered",
    initial_sidebar_state="collapsed",
)

# ============================================
# í•œêµ­ í‘œì¤€ì‹œ (KST) ì„¤ì •
# ============================================
KST = timezone(timedelta(hours=9))

def get_kst_now():
    """í•œêµ­ í‘œì¤€ì‹œ í˜„ì¬ ì‹œê°„ ë°˜í™˜"""
    return datetime.now(KST)

# ============================================
# CSS ìŠ¤íƒ€ì¼
# ============================================
st.markdown(
    """
<style>
/* ì‚¬ì´ë“œë°” ì™„ì „ ìˆ¨ê¹€ */
[data-testid="stSidebar"] {
    display: none;
}
[data-testid="collapsedControl"] {
    display: none;
}

/* ë©”ì¸ ì»¨í…Œì´ë„ˆ */
.main .block-container {
    max-width: 700px;
    padding: 2rem 1rem;
}

/* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ */
.stDownloadButton > button {
    background-color: #4CAF50;
    color: white;
}

/* íŒŒì¼ ì—…ë¡œë” ê°„ì†Œí™” */
.stFileUploader > div {
    padding: 0.5rem;
}

/* ì‘ì—… ìƒíƒœ ì¹´ë“œ */
.job-card {
    border: 1px solid #ddd;
    border-radius: 8px;
    padding: 1rem;
    margin-bottom: 1rem;
}

.job-status-running {
    border-left: 4px solid #4CAF50;
}

.job-status-pending {
    border-left: 4px solid #FFC107;
}

.job-status-completed {
    border-left: 4px solid #2196F3;
}

.job-status-failed {
    border-left: 4px solid #F44336;
}
</style>
""",
    unsafe_allow_html=True,
)

# ============================================
# ì„¤ì • ìƒìˆ˜
# ============================================
MAX_FILES_PER_UPLOAD = 5
DAILY_LIMIT_AUDIO = 30
DAILY_LIMIT_TEXT = 30
MAX_FILE_SIZE_MB = 20
USAGE_FILE = "/tmp/cappy_usage.json"
DOWNLOAD_DIR = "/tmp/cappy_downloads"
METADATA_FILE = "/tmp/cappy_downloads/metadata.json"
EXPIRY_HOURS = 24
DOCX_FONT_NAME = "LGìŠ¤ë§ˆíŠ¸ì²´ Regular"
ADMIN_EMAIL_BCC = "dskam@lgbr.co.kr"
USD_TO_KRW = 1400

# ============================================
# ì‘ì—… ìƒíƒœ ê´€ë¦¬ í•¨ìˆ˜
# ============================================
def create_job(user_emails, file_count, file_type):
    """ìƒˆ ì‘ì—… ìƒì„± ë° ID ë°˜í™˜"""
    job_id = str(uuid.uuid4())
    job_data = {
        'id': job_id,
        'status': 'pending',
        'created_at': get_kst_now().isoformat(),
        'user_emails': user_emails,
        'file_count': file_count,
        'file_type': file_type,
        'progress': 0,
        'current_step': '',
        'result_file': None,
        'error': None,
        'completed_at': None
    }
    
    # Redisì— ì‘ì—… ì •ë³´ ì €ì¥ (24ì‹œê°„ TTL)
    redis_client.setex(f"job:{job_id}", 86400, json.dumps(job_data))
    
    # ì‚¬ìš©ìë³„ ì‘ì—… ëª©ë¡ì— ì¶”ê°€
    user_key = user_emails[0] if user_emails else "anonymous"
    redis_client.lpush(f"user_jobs:{user_key}", job_id)
    redis_client.ltrim(f"user_jobs:{user_key}", 0, 99)  # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
    
    return job_id

def get_job_status(job_id):
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    job_data = redis_client.get(f"job:{job_id}")
    if job_data:
        return json.loads(job_data)
    return None

def update_job_status(job_id, **kwargs):
    """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸"""
    job_data = get_job_status(job_id)
    if job_data:
        job_data.update(kwargs)
        redis_client.setex(f"job:{job_id}", 86400, json.dumps(job_data))

def get_user_jobs(user_email):
    """ì‚¬ìš©ìì˜ ì‘ì—… ëª©ë¡ ì¡°íšŒ"""
    job_ids = redis_client.lrange(f"user_jobs:{user_email}", 0, 20)
    jobs = []
    for job_id in job_ids:
        job_data = get_job_status(job_id)
        if job_data:
            jobs.append(job_data)
    return jobs

# ============================================
# Celery ì‘ì—… ì •ì˜
# ============================================
@app.task(bind=True)
def process_interview_task(self, job_id, files_data, options):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” ì¸í„°ë·° ì²˜ë¦¬ ì‘ì—…"""
    try:
        # ì‘ì—… ì‹œì‘ ìƒíƒœ ì—…ë°ì´íŠ¸
        update_job_status(job_id, status='running', progress=5, current_step='ì‘ì—… ì‹œì‘')
        
        # ì˜µì…˜ ì–¸íŒ¨í‚¹
        file_type = options['file_type']
        is_audio = file_type == 'audio'
        do_transcript = options['do_transcript']
        do_summary = options['do_summary']
        out_md = options['out_md']
        out_docx = options['out_docx']
        out_txt = options['out_txt']
        emails = options['emails']
        transcript_prompt = options.get('transcript_prompt', '')
        summary_prompt = options.get('summary_prompt', '')
        
        results = []
        total_audio_min = 0
        total_in_tok = 0
        total_out_tok = 0
        start_time = time.time()
        
        # íŒŒì¼ ì²˜ë¦¬
        for idx, file_data in enumerate(files_data):
            progress = 10 + (idx * 70 // len(files_data))
            update_job_status(job_id, progress=progress, current_step=f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ({idx+1}/{len(files_data)})')
            
            filename = file_data['name']
            content = file_data['content']
            base_name = filename.rsplit('.', 1)[0]
            
            result = {
                'filename': filename,
                'base_name': base_name,
                'whisper': None,
                'transcript': None,
                'summary': None
            }
            
            # ìŒì„± íŒŒì¼ ì²˜ë¦¬
            if is_audio:
                update_job_status(job_id, current_step=f'ìŒì„± ì¸ì‹ ì¤‘: {filename}')
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(suffix=f'.{filename.split(".")[-1]}', delete=False) as tmp:
                    tmp.write(content)
                    tmp_path = tmp.name
                
                # íŒŒì¼ í¬ê¸° í™•ì¸ ë° ì²˜ë¦¬
                file_size_mb = len(content) / (1024 * 1024)
                if file_size_mb > MAX_FILE_SIZE_MB:
                    # ì²­í¬ ë¶„í•  ì²˜ë¦¬ (ê¸°ì¡´ split_audio_file ë¡œì§ ì‚¬ìš©)
                    text, duration = process_large_audio(tmp_path)
                else:
                    text, duration = transcribe_audio_file(tmp_path)
                
                os.unlink(tmp_path)
                total_audio_min += (duration or 0) / 60
                result['whisper'] = text
                source_text = text
            else:
                # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
                source_text = content.decode('utf-8') if isinstance(content, bytes) else content
            
            if not source_text:
                continue
            
            # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì²˜ë¦¬
            if do_transcript and transcript_prompt:
                update_job_status(job_id, current_step=f'íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘: {filename}')
                transcript = process_with_claude_sync(source_text, transcript_prompt)
                if transcript:
                    result['transcript'] = transcript[0]
                    total_in_tok += transcript[1]
                    total_out_tok += transcript[2]
                    source_text = transcript[0] or source_text
            
            # ìš”ì•½ ì²˜ë¦¬
            if do_summary and summary_prompt:
                update_job_status(job_id, current_step=f'ìš”ì•½ ìƒì„± ì¤‘: {filename}')
                summary = process_with_claude_sync(source_text, summary_prompt)
                if summary and summary[0]:
                    if result['transcript']:
                        header = extract_header_from_transcript(result['transcript'])
                        summary_text = add_header_to_summary(summary[0], header)
                    else:
                        summary_text = summary[0]
                    result['summary'] = summary_text
                    total_in_tok += summary[1]
                    total_out_tok += summary[2]
            
            results.append(result)
        
        # ê²°ê³¼ íŒŒì¼ ìƒì„±
        update_job_status(job_id, progress=85, current_step='ê²°ê³¼ íŒŒì¼ ìƒì„± ì¤‘')
        
        if results:
            # ZIP íŒŒì¼ ìƒì„±
            zip_buffer = create_result_zip(results, options)
            
            # íŒŒì¼ ì €ì¥
            first_filename = results[0]['filename']
            zip_filename = generate_zip_filename(emails, first_filename)
            
            # ê²°ê³¼ íŒŒì¼ ì €ì¥
            result_file_path = os.path.join(DOWNLOAD_DIR, f"{job_id}_{zip_filename}")
            with open(result_file_path, 'wb') as f:
                f.write(zip_buffer.getvalue())
            
            # ì´ë©”ì¼ ë°œì†¡
            update_job_status(job_id, progress=95, current_step='ì´ë©”ì¼ ë°œì†¡ ì¤‘')
            
            elapsed = time.time() - start_time
            costs = calculate_costs(total_audio_min, total_in_tok, total_out_tok)
            
            # ì´ë©”ì¼ ë³¸ë¬¸ ë° ì²¨ë¶€íŒŒì¼ ì¤€ë¹„
            all_attachments = prepare_email_attachments(results, options)
            all_attachments.append((zip_filename, zip_buffer.getvalue()))
            
            body = generate_email_body_for_task(
                results, len(files_data), file_type, 
                do_transcript, do_summary, options,
                int(elapsed // 60), int(elapsed % 60), costs
            )
            
            # ì´ë©”ì¼ ë°œì†¡
            send_email(
